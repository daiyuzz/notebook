# 机器学习中调参的基本思想


## 1.找目标
我们要做什么?一般来说,这个目标是提升某个模型评估指标,比如对于随机森林,我们想要提升的是模型在未知数据上的准确率(由score或obb_score来衡量),找准这个目标,我们就需要思考:模型在未知数据上的准确率受什么因素影响?在机器学习中,我们用来**衡量在未知数据上的准确率**的指标,叫做**泛化误差**

### 泛化误差
当在未知数据(测试集或袋外数据)上表现糟糕时,我们说模型的泛化程度不够,泛化误差大,模型的效果不好,泛化误差收到模型的结构(复杂度)的影响,看下面这张图,它准确的描述了泛化误差与模型复杂度的关系,当模型太复杂,模型就会过拟合,泛化能力就不够,所以泛化误差很大,当模型简单,模型就会欠拟合,拟合能力就不够,所以误差也会大.只有当模型复杂程度刚刚好才能后达到泛化误差最小的目标.

![](assets/20200330151410600_1808656122.png =600x)

那模型复杂程度与我们的参数有什么关系呢?对树模型来说,树越茂盛,深度越深,枝叶越多,模型就越复杂.所以树模型是天生位于上图右上角的模型,随机森林是以树模型为基础的,所以随机森林也是天生复杂度高的模型.随机森林的参数,都是向着一个目标去:减少模型的复杂度,把模型往图像左边移动,防止过拟合.当然了,调参没有绝对的,也有天生处于图像左边的随机森林,所以调参之前,我们要先判断,模型现在究竟处于图像哪一边.

泛化误差的背后其实是"偏差-方差困境",原理十分复杂,无论你翻开哪一本书,都会看见长篇的数学论证和看不懂的文字解释,
我们只需要记住下面这四点:
- 1.模型太复杂或太简单,都会让泛化误差高,我们追求的是位于中间的平衡点.
- 2.模型太复杂就会过拟合,模型太简单就会欠拟合
- 3.对树模型和树的集成模型来说,树的深度越深,枝叶越多,模型越复杂
- 4.树模型和树的集成模型的目标,都是减少模型的复杂度,把模型往图像左边移动


![](assets/20200330153242096_1732263418.png =800x)

有了以上的知识储备,我们现在也能够通过参数的变化来了解,模型什么时候达到极限,当复杂度已经不能再降低的时候,我们就不必再调整了,因为调整大型数据的参数是一个非常费时费力的事情.