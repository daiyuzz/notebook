## 实战：爬取京东商品和评论

### 爬虫思路：

```python
使用 scrapy, scrapy-redis, graphite 实现的京东分布式爬虫，以 mongodb 实现底层存储。分布式 实现，解决带宽和性能的瓶颈，提高爬取的效率。实现 scrapy-redis 对进行 url 的去重 以及调度，利用redis的高效和易于扩展能够轻松实现高效率下载：当redis存储或者访问速 度遇到瓶颈时，可以通过增大redis集群数和爬虫集群数量改善
```

### 爬取策略

```python
获取 <a href> 标签里面的 url 值，然后迭代爬取，并且把 url 限定在
  xxx.jd.com 范围内，防止无限广度的问题。
```

#### 请求去重策略：

```python
使用 `scrapy_redis.dupefilter.RFPDupeFilter` 实现去重，请求入队列的逻辑－ enqueue_request, 而具体的去重逻辑是调用 scrapy.utils.request.request.fingerprint
```

#### 商品去重策略

```python
使用 Redis 进行商品去重，将商品的 sku-id 放入Redis, 在将整个商品数据插入到 Mongodb 之前，先检查 Redis 里sku-id 是否已存在
```

#### 反反爬策略

###### 禁用cookie

```python
通过禁用 cookie, 服务器就无法根据 cookie 判断出爬虫是否访问过网站
```

###### 伪装成搜索引擎

```python
'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',
'Mozilla/5.0 (compatible; Bingbot/2.0; +http://www.bing.com/bingbot.htm)',
'Mozilla/5.0 (compatible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp)',
'DuckDuckBot/1.0; (+http://duckduckgo.com/duckduckbot.html)',
'Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)',
'Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots)',
'ia_archiver (+http://www.alexa.com/site/help/webmasters; crawler@alexa.com)',
```

###### 轮转user-agent

```python
为了提高突破反爬虫策略的成功率，定义多个user-agent, 然后每次请求都随机选择 user-agent。本爬虫实现了一个 RotateUserAgentMiddleware 类来实现 user-agent 的轮转
```

###### 代理IP

```python
使用代理IP，防止IP被封
```



### 并发请求和深度控制

```python
通过 setting.py 中的 CONCURRENT_REQUESTS = 32 配置来控制并发请求数量，通过 DepthMiddle 类的 DEPTH_LIMIT=max 参数来控制爬虫的的递归深
```



### 